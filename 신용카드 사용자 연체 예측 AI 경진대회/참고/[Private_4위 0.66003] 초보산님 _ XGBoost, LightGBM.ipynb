{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, glob, warnings\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style = 'whitegrid')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    trn = pd.read_csv('train.csv')\n",
    "    tst = pd.read_csv('test.csv')\n",
    "    \n",
    "    #불필요한 칼럼 삭제\n",
    "    drop_cols = ['FLAG_MOBIL', 'index', 'child_num']\n",
    "    trn.drop(drop_cols, axis = 1, inplace = True)\n",
    "    tst.drop(drop_cols, axis = 1, inplace = True)\n",
    "    \n",
    "    #occyp_type null값 처리\n",
    "    trn['occyp_type'].fillna('BLANK', inplace = True)\n",
    "    tst['occyp_type'].fillna('BLANK', inplace = True)    \n",
    "    return trn, tst\n",
    "\n",
    "def freq_encoding(df, col, normalize = True):    \n",
    "    vc = df[col].value_counts(normalize = normalize).to_dict()\n",
    "    nm = col + '_FE'\n",
    "    df[nm] = df[col].map(vc)    \n",
    "    return df\n",
    "\n",
    "xgb_params = {\n",
    "    'booster' : 'gbtree',\n",
    "    'tree_method' : 'gpu_hist',\n",
    "    'predictor' : 'gpu_predictor',    \n",
    "    'objective' : 'multi:softprob',\n",
    "    'eval_metric' : 'mlogloss',\n",
    "    'n_estimators' : 5000,\n",
    "    'max_depth' : 9,\n",
    "    'min_child_weight' : 5,    \n",
    "    'learning_rate' : 0.012727,    \n",
    "    'subsample' : 0.91020,\n",
    "    'colsample_bytree' : 0.77959,    \n",
    "    'colsample_bylevel' : 0.64898,\n",
    "    'lambda' : 0.05,\n",
    "    'alpha' : 1,    \n",
    "    'seed' : 2018\n",
    "}\n",
    "\n",
    "lgbm_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'eval_metric' : 'logloss',    \n",
    "    'n_estimators': 10000,\n",
    "    'early_stopping_round': 100, \n",
    "    'max_depth': -1,\n",
    "    'max_bin': 255,\n",
    "    'boost_from_average' : False,\n",
    "    'bagging_freq' : 1,\n",
    "    'min_data_in_leaf': 40,    \n",
    "    'learning_rate': 0.02272,    \n",
    "    'num_leaves': 64,    \n",
    "    'feature_fraction': 0.89387,\n",
    "    'bagging_fraction': 0.76326,        \n",
    "    'seed': 2018,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,    \n",
    "}\n",
    "\n",
    "def train_model(model, trn, tst, cv = 5):\n",
    "    tst_preds = []\n",
    "    vld_preds = []\n",
    "    feats_importance = np.zeros(tst.shape[1])    \n",
    "    for n, (trn_idx, vld_idx) in enumerate(StratifiedKFold(cv).split(trn.drop('credit', axis = 1).values, trn['credit'].values)):\n",
    "        print(f\"{n+1}/{cv}번째 폴드 시작..........\")        \n",
    "        X_trn = trn.loc[trn_idx, :].drop('credit', axis = 1)\n",
    "        X_vld = trn.loc[vld_idx, :].drop('credit', axis = 1)\n",
    "        y_trn = trn.loc[trn_idx, 'credit'].values\n",
    "        y_vld = trn.loc[vld_idx, 'credit'].values\n",
    "        \n",
    "        model.fit(\n",
    "            X_trn, y_trn,\n",
    "            eval_set = [(X_trn, y_trn), (X_vld, y_vld)],\n",
    "            verbose = 500, early_stopping_rounds = 30\n",
    "        )    \n",
    "        vld_preds.append(log_loss(y_vld, model.predict_proba(X_vld)))        \n",
    "        \n",
    "        tst_pred = model.predict_proba(tst)\n",
    "        tst_preds.append(tst_pred)\n",
    "        feats_importance += model.feature_importances_                        \n",
    "        \n",
    "    feats_importance = feats_importance / cv\n",
    "    feats_importance = pd.Series(data = feats_importance, index = tst.columns)\n",
    "\n",
    "    print('5폴더 평균 mlogloss: ', np.mean(vld_preds))\n",
    "    return tst_preds, feats_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36457, 8876)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>credit</th>\n",
       "      <th>YEARS_EMPLOYED</th>\n",
       "      <th>YEARS_BIRTH</th>\n",
       "      <th>MONTHS_EMPLOYED</th>\n",
       "      <th>MONTHS_BIRTH</th>\n",
       "      <th>WEEKS_EMPLOYED</th>\n",
       "      <th>WEEKS_BIRTH</th>\n",
       "      <th>EMPLOYED_RATIO</th>\n",
       "      <th>income_per_family</th>\n",
       "      <th>...</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_10DAYS_EMPLOYED</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_60DAYS_EMPLOYED</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_90DAYS_EMPLOYED</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#mean#family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#std#family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#var#family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#max#family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#min#family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#ptp#family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#medianfamily_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#skewfamily_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_10family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_60family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_90family_size</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#mean#begin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#std#begin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#var#begin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#max#begin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#min#begin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#ptp#begin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#medianbegin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#skewbegin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_10begin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_60begin_month</th>\n",
       "      <th>income_per_weeks_birth_income_per_years_birth#percentile_90begin_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13899</td>\n",
       "      <td>4709.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>201</td>\n",
       "      <td>940</td>\n",
       "      <td>797</td>\n",
       "      <td>8510</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4709.0</td>\n",
       "      <td>4709.0</td>\n",
       "      <td>4709.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-33.200000</td>\n",
       "      <td>19.942417</td>\n",
       "      <td>397.700000</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>0.175234</td>\n",
       "      <td>-53.2</td>\n",
       "      <td>-28.6</td>\n",
       "      <td>-13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11380</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>358</td>\n",
       "      <td>117</td>\n",
       "      <td>452</td>\n",
       "      <td>441</td>\n",
       "      <td>5432</td>\n",
       "      <td>339</td>\n",
       "      <td>...</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.181818</td>\n",
       "      <td>3.311138</td>\n",
       "      <td>10.963636</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-0.593003</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 8876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  car  reality  income_total  income_type  edu_type  family_type  \\\n",
       "0       0    0        0      202500.0            0         1            1   \n",
       "1       0    0        1      247500.0            0         4            0   \n",
       "\n",
       "   house_type  DAYS_BIRTH  DAYS_EMPLOYED  work_phone  phone  email  \\\n",
       "0           2       13899         4709.0           0      0      0   \n",
       "1           1       11380         1540.0           0      0      1   \n",
       "\n",
       "   occyp_type  family_size  begin_month  credit  YEARS_EMPLOYED  YEARS_BIRTH  \\\n",
       "0           1          2.0         -6.0     1.0               4           18   \n",
       "1           9          3.0         -5.0     1.0              34           11   \n",
       "\n",
       "   MONTHS_EMPLOYED  MONTHS_BIRTH  WEEKS_EMPLOYED  WEEKS_BIRTH  EMPLOYED_RATIO  \\\n",
       "0               64           201             940          797            8510   \n",
       "1              358           117             452          441            5432   \n",
       "\n",
       "   income_per_family  ...  \\\n",
       "0                  0  ...   \n",
       "1                339  ...   \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_10DAYS_EMPLOYED  \\\n",
       "0                                             4709.0                          \n",
       "1                                             1540.0                          \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_60DAYS_EMPLOYED  \\\n",
       "0                                             4709.0                          \n",
       "1                                             1540.0                          \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_90DAYS_EMPLOYED  \\\n",
       "0                                             4709.0                          \n",
       "1                                             1540.0                          \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#mean#family_size  \\\n",
       "0                                                2.0                \n",
       "1                                                3.0                \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#std#family_size  \\\n",
       "0                                                0.0               \n",
       "1                                                0.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#var#family_size  \\\n",
       "0                                                0.0               \n",
       "1                                                0.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#max#family_size  \\\n",
       "0                                                2.0               \n",
       "1                                                3.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#min#family_size  \\\n",
       "0                                                2.0               \n",
       "1                                                3.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#ptp#family_size  \\\n",
       "0                                                0.0               \n",
       "1                                                0.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#medianfamily_size  \\\n",
       "0                                                2.0                 \n",
       "1                                                3.0                 \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#skewfamily_size  \\\n",
       "0                                                0.0               \n",
       "1                                                0.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_10family_size  \\\n",
       "0                                                2.0                        \n",
       "1                                                3.0                        \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_60family_size  \\\n",
       "0                                                2.0                        \n",
       "1                                                3.0                        \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_90family_size  \\\n",
       "0                                                2.0                        \n",
       "1                                                3.0                        \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#mean#begin_month  \\\n",
       "0                                         -33.200000                \n",
       "1                                          -7.181818                \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#std#begin_month  \\\n",
       "0                                          19.942417               \n",
       "1                                           3.311138               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#var#begin_month  \\\n",
       "0                                         397.700000               \n",
       "1                                          10.963636               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#max#begin_month  \\\n",
       "0                                               -6.0               \n",
       "1                                               -3.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#min#begin_month  \\\n",
       "0                                              -58.0               \n",
       "1                                              -13.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#ptp#begin_month  \\\n",
       "0                                               52.0               \n",
       "1                                               10.0               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#medianbegin_month  \\\n",
       "0                                              -31.0                 \n",
       "1                                               -6.0                 \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#skewbegin_month  \\\n",
       "0                                           0.175234               \n",
       "1                                          -0.593003               \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_10begin_month  \\\n",
       "0                                              -53.2                        \n",
       "1                                              -11.0                        \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_60begin_month  \\\n",
       "0                                              -28.6                        \n",
       "1                                               -5.0                        \n",
       "\n",
       "   income_per_weeks_birth_income_per_years_birth#percentile_90begin_month  \n",
       "0                                              -13.6                       \n",
       "1                                               -4.0                       \n",
       "\n",
       "[2 rows x 8876 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn, tst = load_data()\n",
    "\n",
    "features = trn.drop('credit', axis = 1).columns\n",
    "sole_cols = ['gender', 'phone', 'work_phone', 'email', 'house_type']\n",
    "cat_cols = ['car', 'reality', 'income_type', 'edu_type', 'family_type', 'occyp_type',            \n",
    "            'YEARS_EMPLOYED', 'YEARS_BIRTH',\n",
    "            'MONTHS_EMPLOYED', 'MONTHS_BIRTH',\n",
    "            'WEEKS_EMPLOYED', 'WEEKS_BIRTH',            \n",
    "            'income_per_family', 'EMPLOYED_RATIO',\n",
    "            'income_per_days_birth',\n",
    "            'income_per_weeks_birth',\n",
    "            'income_per_years_birth',\n",
    "           ]\n",
    "\n",
    "df = pd.concat([trn, tst]).reset_index(drop = True)\n",
    "\n",
    "#숫자형 피처 전처리\n",
    "df.loc[df['DAYS_EMPLOYED'] == 365243, 'DAYS_EMPLOYED'] = df[df.DAYS_EMPLOYED != 365243]['DAYS_EMPLOYED'].mean()\n",
    "df['DAYS_EMPLOYED'] = df['DAYS_EMPLOYED'].map(lambda x: -1 * x if x <0 else x)\n",
    "df['DAYS_BIRTH'] = df['DAYS_BIRTH'].map(lambda x: -1 * x if x <0 else x)\n",
    "\n",
    "df['YEARS_EMPLOYED'] = df['DAYS_EMPLOYED'].map(lambda x: int(x/365))\n",
    "df['YEARS_BIRTH'] = df['DAYS_BIRTH'].map(lambda x: int(x/365))\n",
    "\n",
    "df['MONTHS_EMPLOYED'] = df['DAYS_EMPLOYED'].map(lambda x: int(x/30))\n",
    "df['MONTHS_BIRTH'] = df['DAYS_BIRTH'].map(lambda x: int(x/30))\n",
    "\n",
    "df['WEEKS_EMPLOYED'] = df['DAYS_EMPLOYED'].map(lambda x: int(x/7))\n",
    "df['WEEKS_BIRTH'] = df['DAYS_BIRTH'].map(lambda x: int(x/7))\n",
    "\n",
    "df['EMPLOYED_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['income_per_family'] = df['income_total'] / df['family_size']\n",
    "df['income_per_days_birth'] = df['income_total'] / df['DAYS_BIRTH']\n",
    "df['income_per_weeks_birth'] = df['income_total'] / df['WEEKS_BIRTH']\n",
    "df['income_per_years_birth'] = df['income_total'] / df['YEARS_BIRTH']\n",
    "\n",
    "num_cols = [col for col in features if col not in cat_cols + sole_cols]\n",
    "   \n",
    "for col in sole_cols + cat_cols:\n",
    "    df[col] = df[col].astype(str)\n",
    "    df = freq_encoding(df, col)\n",
    "\n",
    "# 조합형 변수 생성\n",
    "comb_num = 2\n",
    "for col in list(combinations(cat_cols, comb_num)):\n",
    "    new_col = col[0]\n",
    "    for n in range(1, comb_num):\n",
    "        new_col = new_col + \"_\" + col[n]\n",
    "    df[new_col] = df[col[0]].astype(str)\n",
    "    for n in range(1, comb_num):\n",
    "        df[new_col] = df[new_col] + \"_\" + df[col[n]].astype(str)\n",
    "    cat_cols.append(new_col)\n",
    "       \n",
    "# 카테고리 변수와 숫자형 변수 조합\n",
    "for cat_col in sole_cols + cat_cols:\n",
    "    for num_col in num_cols:        \n",
    "        new_name = cat_col + \"#mean#\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].mean()\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#std#\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].std(ddof = 1)\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#var#\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].var(ddof = 1)\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#max#\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].max()\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#min#\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].min()\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#ptp#\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].agg(np.ptp)\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#median\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].median()\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#skew\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].skew()\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#percentile_10\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].agg(lambda x: np.percentile(x, 10))\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#percentile_60\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].agg(lambda x: np.percentile(x, 60))\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "        \n",
    "        new_name = cat_col + \"#percentile_90\" + num_col\n",
    "        grouped = df.groupby(cat_col)[num_col].agg(lambda x: np.percentile(x, 90))\n",
    "        df[new_name] = df[cat_col].map(grouped)\n",
    "         \n",
    "le_dict = {} #LabelEncoder를 저장하는 사전\n",
    "for col in sole_cols + cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].values)\n",
    "    le_dict[col] = le    \n",
    "\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "(26457, 8876) (10000, 8875)\n",
      "1/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttraining's multi_logloss: 0.430961\tvalid_1's multi_logloss: 0.672956\n",
      "2/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's multi_logloss: 0.410859\tvalid_1's multi_logloss: 0.651845\n",
      "3/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[305]\ttraining's multi_logloss: 0.414168\tvalid_1's multi_logloss: 0.637326\n",
      "4/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttraining's multi_logloss: 0.437836\tvalid_1's multi_logloss: 0.677995\n",
      "5/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[274]\ttraining's multi_logloss: 0.43019\tvalid_1's multi_logloss: 0.659985\n",
      "6/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttraining's multi_logloss: 0.449333\tvalid_1's multi_logloss: 0.687456\n",
      "7/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\ttraining's multi_logloss: 0.422888\tvalid_1's multi_logloss: 0.638614\n",
      "8/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\ttraining's multi_logloss: 0.428082\tvalid_1's multi_logloss: 0.675336\n",
      "9/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttraining's multi_logloss: 0.439747\tvalid_1's multi_logloss: 0.65662\n",
      "10/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttraining's multi_logloss: 0.43769\tvalid_1's multi_logloss: 0.669444\n",
      "11/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\ttraining's multi_logloss: 0.418089\tvalid_1's multi_logloss: 0.664983\n",
      "12/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's multi_logloss: 0.439377\tvalid_1's multi_logloss: 0.680238\n",
      "13/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's multi_logloss: 0.416791\tvalid_1's multi_logloss: 0.644675\n",
      "14/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\ttraining's multi_logloss: 0.426952\tvalid_1's multi_logloss: 0.657352\n",
      "15/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\ttraining's multi_logloss: 0.422429\tvalid_1's multi_logloss: 0.665549\n",
      "16/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's multi_logloss: 0.437436\tvalid_1's multi_logloss: 0.663197\n",
      "17/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\ttraining's multi_logloss: 0.422664\tvalid_1's multi_logloss: 0.669904\n",
      "18/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's multi_logloss: 0.474072\tvalid_1's multi_logloss: 0.68614\n",
      "19/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[312]\ttraining's multi_logloss: 0.40982\tvalid_1's multi_logloss: 0.668227\n",
      "20/20번째 폴드 시작..........\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] feature_fraction is set=0.89387, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.89387\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.76326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.76326\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[307]\ttraining's multi_logloss: 0.412376\tvalid_1's multi_logloss: 0.654712\n",
      "5폴더 평균 mlogloss:  0.6641276217907056\n",
      "1/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09143\tvalidation_1-mlogloss:1.09206\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45446\tvalidation_1-mlogloss:0.67896\n",
      "Stopping. Best iteration:\n",
      "[670]\tvalidation_0-mlogloss:0.41504\tvalidation_1-mlogloss:0.67597\n",
      "\n",
      "2/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09142\tvalidation_1-mlogloss:1.09201\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45451\tvalidation_1-mlogloss:0.65730\n",
      "Stopping. Best iteration:\n",
      "[775]\tvalidation_0-mlogloss:0.39721\tvalidation_1-mlogloss:0.65029\n",
      "\n",
      "3/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09137\tvalidation_1-mlogloss:1.09180\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45659\tvalidation_1-mlogloss:0.64633\n",
      "Stopping. Best iteration:\n",
      "[732]\tvalidation_0-mlogloss:0.40525\tvalidation_1-mlogloss:0.63911\n",
      "\n",
      "4/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09146\tvalidation_1-mlogloss:1.09220\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45640\tvalidation_1-mlogloss:0.68100\n",
      "Stopping. Best iteration:\n",
      "[653]\tvalidation_0-mlogloss:0.42008\tvalidation_1-mlogloss:0.67819\n",
      "\n",
      "5/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09147\tvalidation_1-mlogloss:1.09204\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45515\tvalidation_1-mlogloss:0.66551\n",
      "Stopping. Best iteration:\n",
      "[674]\tvalidation_0-mlogloss:0.41465\tvalidation_1-mlogloss:0.66121\n",
      "\n",
      "6/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09139\tvalidation_1-mlogloss:1.09221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45497\tvalidation_1-mlogloss:0.69125\n",
      "Stopping. Best iteration:\n",
      "[650]\tvalidation_0-mlogloss:0.41959\tvalidation_1-mlogloss:0.68857\n",
      "\n",
      "7/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09146\tvalidation_1-mlogloss:1.09192\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45842\tvalidation_1-mlogloss:0.64426\n",
      "Stopping. Best iteration:\n",
      "[703]\tvalidation_0-mlogloss:0.41258\tvalidation_1-mlogloss:0.63891\n",
      "\n",
      "8/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09143\tvalidation_1-mlogloss:1.09217\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45441\tvalidation_1-mlogloss:0.67841\n",
      "Stopping. Best iteration:\n",
      "[666]\tvalidation_0-mlogloss:0.41598\tvalidation_1-mlogloss:0.67567\n",
      "\n",
      "9/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09138\tvalidation_1-mlogloss:1.09197\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45945\tvalidation_1-mlogloss:0.66380\n",
      "Stopping. Best iteration:\n",
      "[676]\tvalidation_0-mlogloss:0.41899\tvalidation_1-mlogloss:0.65899\n",
      "\n",
      "10/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09153\tvalidation_1-mlogloss:1.09220\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45631\tvalidation_1-mlogloss:0.67636\n",
      "Stopping. Best iteration:\n",
      "[615]\tvalidation_0-mlogloss:0.42864\tvalidation_1-mlogloss:0.67371\n",
      "\n",
      "11/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09145\tvalidation_1-mlogloss:1.09206\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45594\tvalidation_1-mlogloss:0.67049\n",
      "Stopping. Best iteration:\n",
      "[655]\tvalidation_0-mlogloss:0.41871\tvalidation_1-mlogloss:0.66700\n",
      "\n",
      "12/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09141\tvalidation_1-mlogloss:1.09222\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45719\tvalidation_1-mlogloss:0.67965\n",
      "Stopping. Best iteration:\n",
      "[658]\tvalidation_0-mlogloss:0.41793\tvalidation_1-mlogloss:0.67716\n",
      "\n",
      "13/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09133\tvalidation_1-mlogloss:1.09197\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45877\tvalidation_1-mlogloss:0.65480\n",
      "Stopping. Best iteration:\n",
      "[758]\tvalidation_0-mlogloss:0.40277\tvalidation_1-mlogloss:0.64517\n",
      "\n",
      "14/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09148\tvalidation_1-mlogloss:1.09205\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45654\tvalidation_1-mlogloss:0.66708\n",
      "Stopping. Best iteration:\n",
      "[730]\tvalidation_0-mlogloss:0.40404\tvalidation_1-mlogloss:0.66095\n",
      "\n",
      "15/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09148\tvalidation_1-mlogloss:1.09205\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45771\tvalidation_1-mlogloss:0.66658\n",
      "Stopping. Best iteration:\n",
      "[744]\tvalidation_0-mlogloss:0.40333\tvalidation_1-mlogloss:0.66111\n",
      "\n",
      "16/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09144\tvalidation_1-mlogloss:1.09219\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45721\tvalidation_1-mlogloss:0.67023\n",
      "Stopping. Best iteration:\n",
      "[657]\tvalidation_0-mlogloss:0.42025\tvalidation_1-mlogloss:0.66631\n",
      "\n",
      "17/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09140\tvalidation_1-mlogloss:1.09225\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45721\tvalidation_1-mlogloss:0.67754\n",
      "Stopping. Best iteration:\n",
      "[685]\tvalidation_0-mlogloss:0.41333\tvalidation_1-mlogloss:0.67336\n",
      "\n",
      "18/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09133\tvalidation_1-mlogloss:1.09214\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45387\tvalidation_1-mlogloss:0.68883\n",
      "Stopping. Best iteration:\n",
      "[515]\tvalidation_0-mlogloss:0.44939\tvalidation_1-mlogloss:0.68879\n",
      "\n",
      "19/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09136\tvalidation_1-mlogloss:1.09220\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45512\tvalidation_1-mlogloss:0.67597\n",
      "Stopping. Best iteration:\n",
      "[771]\tvalidation_0-mlogloss:0.39823\tvalidation_1-mlogloss:0.66831\n",
      "\n",
      "20/20번째 폴드 시작..........\n",
      "[0]\tvalidation_0-mlogloss:1.09137\tvalidation_1-mlogloss:1.09207\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[500]\tvalidation_0-mlogloss:0.45628\tvalidation_1-mlogloss:0.66372\n",
      "Stopping. Best iteration:\n",
      "[747]\tvalidation_0-mlogloss:0.40295\tvalidation_1-mlogloss:0.65781\n",
      "\n",
      "5폴더 평균 mlogloss:  0.6653297138250301\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "df = pd.read_pickle('data.pkl').reset_index(drop = True)\n",
    "\n",
    "# learning\n",
    "trn = df[df.credit.notna()]\n",
    "tst = df[df.credit.isna()].drop('credit', axis = 1)\n",
    "print(trn.shape, tst.shape)\n",
    "\n",
    "tst_preds_lgbm, feat_im_lgbm = train_model(LGBMClassifier(**lgbm_params), trn, tst, cv = 20)\n",
    "tst_preds_xgb, feat_im_xgb = train_model(XGBClassifier(**xgb_params), trn, tst, cv = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(xgb_preds, lgbm_preds, xgb_ratio=0.5, cv=5):\n",
    "    xgb_result = np.zeros((10000, 3))\n",
    "    for xgb_pred in xgb_preds:\n",
    "        xgb_result += xgb_pred\n",
    "    xgb_result /= cv\n",
    "    lgbm_result = np.zeros((10000, 3))\n",
    "    for lgbm_pred in lgbm_preds:\n",
    "        lgbm_result += lgbm_pred\n",
    "    lgbm_result /= cv    \n",
    "    result = xgb_result * xgb_ratio + lgbm_result * (1 - xgb_ratio)\n",
    "    \n",
    "    submission = pd.read_csv('sample_submission.csv', index_col = 'index')\n",
    "    submission = pd.DataFrame(\n",
    "        index = submission.index,\n",
    "        columns = submission.columns,\n",
    "        data = result\n",
    "    )\n",
    "    submission.to_csv('submission.csv')\n",
    "make_submission(tst_preds_xgb, tst_preds_lgbm, 0.5, cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
