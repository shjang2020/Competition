{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "klue/roberta를 이용한 베이스라인입니다. \n",
    "- transformers : Huggingface에 등록된 pretrained model/tokenizer를 불러올 수 있는 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# for graphing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_or = pd.read_csv('data/train.csv')\n",
    "train_or.drop(columns=['ID'], inplace=True)\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test.drop(columns=['ID'], inplace=True)\n",
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 3, 2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_or.유형.nunique(),train_or.극성.nunique(),train_or.시제.nunique(),train_or.확실성.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_or.label.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드를 돌린 디바이스가 m1 mac이므로 torch.device('mps')를 썼지만 맥이 아닌 gpu를 쓸때는 'cuda'를 쓰면 된다. gpu가 없다면 'cpu'로 설정하면 되는데 그러면 속도가 많이 느려질 것이다. gpu가 있는지 알아보기 위해서는 torch.cuda.is_available()를 돌려보면 true 아니면 false가 나올 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "CFG = {\n",
    "    'EPOCHS':5,\n",
    "    'LEARNING_RATE':1e-5,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':42\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 있는지 확인하는 코드\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음으로는 train_test_split를 이용해서 train와 val을 나눠줍니다. \n",
    "\n",
    "유형(type), 극성(polarity), 시제(tense), 확실성(certainty) 중에서 imbalanced한 label도 있기때문에\n",
    "\n",
    "stratify를 추가해주는게 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(train_or, train_or['label'], test_size=0.2, random_state=CFG['SEED'])\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.label.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 언급했듯이 transformers 패키지를 통해서 pretrained된 모델을 불러올 수 있다.\n",
    "\n",
    "불러오는 방법은 https://huggingface.co/models 여기서 model 이름을 검색하고 \n",
    "\n",
    "모델은 AutoModel.from_pretrained()을 통해서, 토크나이저는 AutoTokenizer.from_pretrained()을 통해서 \n",
    "\n",
    "모델이름을 파라미터로 넣어주면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_nm = 'klue/roberta-small'\n",
    "base_model = AutoModel.from_pretrained(model_nm)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토크나이저의 역할은 문장을 토큰이라고 하는 작은 단위 (더이상 나눌 수 없는 가장 작은 단위)로 나누어주고 pretrained tokenizer에 그 토큰이 어디에 저장되어 있는지 input_ids로 되돌려준다.\n",
    "\n",
    "밑 코드는 그 input_ids 길이가 어떤지 histogram으로 그려본 것이다.\n",
    "\n",
    "(저도 이 분야는 신생아라 틀린 부분이 있을 수 있습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log value : 91.48731761060522\n"
     ]
    }
   ],
   "source": [
    "tokenizer_len = [len(tokenizer(s)['input_ids']) for s in train['문장']]\n",
    "sns.histplot(tokenizer_len)\n",
    "plt.show()\n",
    "\n",
    "print(f'log value : {np.mean(tokenizer_len)+3*np.std(tokenizer_len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서, log를 취해주면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log value : 4.909803820030983\n",
      "original value : 135.61280728232697\n"
     ]
    }
   ],
   "source": [
    "tokenizer_log = np.log(tokenizer_len)\n",
    "sns.histplot(tokenizer_log)\n",
    "plt.show()\n",
    "\n",
    "print(f'log value : {np.mean(tokenizer_log)+3*np.std(tokenizer_log)}')\n",
    "print(f'original value : {np.exp(np.mean(tokenizer_log)+3*np.std(tokenizer_log))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**따라서, 적정선은 91에서 135 사이가 아닐까 생각된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 값은 잠깐 뒤로하고 아래 코드를 위부터 설명하자면,\n",
    "\n",
    "torch.utils.data의 Dataset의 child class인 SentenceTypeDataset을 만들어준다. 이는 pytorch neural network에 내 맘대로 \n",
    "x가 뭔지 y가 뭔지 정한 dataset을 제공하기 위한 클래스이다. 만드는데 꼭 필요한 function은 총 3가지이다.\n",
    "\n",
    "_ _ init _ _()\n",
    "- x랑 y가 뭔지 저장해줘야 한다. \n",
    "- 이때 이번에는 텍스트 데이터를 다뤄주기때문에 dataframe, tokenizer, labels를 parameter로 넣어줬고 dataframe의 문장을 tokenizer로 토큰화 시킨다음 self.texts에 저장해주고 입력받은 labels는 그대로 self.labels에 저장해줬다. \n",
    "- batch에 들어가는 입력들은 input size가 다 같아야 한다. 따라서 tokenizer로 나온 값들을 그대로 넣어버리면 오류가 난다. 위 히스토그램에서 볼 수 있듯이 문장마다 다르기 때문. 따라서 위 값(90)으로 tokenizer의 max_length를 정해주고 max_length보다 작은 길이들은 padding으로 채워주고 긴 길이들은 truncation으로 잘라준다. 이때 max_length는 길면 길수록 training time이 늘어난다.\n",
    "- tokenizer안에 return_tensors의 pt는 tensor로 tokenizer값을 리턴해준다는 뜻이다.\n",
    "\n",
    "_ _ len _ _()\n",
    "- self.texts의 길이는 리턴해줍니다.\n",
    "\n",
    "_ _ getitem _ _()\n",
    "- idx에 해당되는 x와 y를 리턴해줍니다.\n",
    "- x는 self.texts에서 가져오고 y는 그 텍스트(x)에 해당되는 유형, 극성, 시제, 확실성을 리턴하면 됩니다.\n",
    "- 나중 코드에서 나오겠지만 미리 설명을 하자면 labels는 train, val set에서만 dictionary형태로 주어진다. 이때 유형, 극성, 시제, 확실성이 key고 해당 레이블에 해당되는 값을 one-hot encoding한게 value다. \n",
    "- dictionary에 저장된 형태는 list고 pytorch에는 tensor 형태로 넣어줘야하기 때문에 torch.Tensor()로 형태를 바꾸어준다.\n",
    "- test set의 경우 labels이 주어지지 않기 때문에 똑같은 길이지만 -1로 채워놓은 tensor를 리턴해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTypeDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, labels=None):\n",
    "        texts = dataframe['문장'].values.tolist()\n",
    "\n",
    "        self.texts = [tokenizer(text, padding='max_length', max_length=90, truncation=True, return_tensors='pt') for text in texts]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "\n",
    "        if self.labels is not None:\n",
    "            type_tmp = self.labels['type'][idx]\n",
    "            polarity_tmp = self.labels['polarity'][idx]\n",
    "            tense_tmp = self.labels['tense'][idx]\n",
    "            certainty_tmp = self.labels['certainty'][idx]\n",
    "            return text, torch.Tensor(type_tmp), torch.Tensor(polarity_tmp), torch.Tensor(tense_tmp), torch.Tensor(certainty_tmp)\n",
    "        else:\n",
    "            return text, torch.Tensor([-1,-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1,-1]), torch.Tensor([-1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로는 Classifier class를 만드는 것이다.\n",
    "\n",
    "\\__init__()\n",
    "- 우선 nn.Module의 child class이기 때문에 \\__init__() 안에 super().\\__init__()을 불러주고 base_model을 통해서 받을 pretrained_model을 self.klue에 저장한다.\n",
    "이때 klue의 output features는 768이다. 확인방법은 base_model을 셀에 쳐보면 된다. (더 쉬운 방법이 있으면 알려주세요)\n",
    "\n",
    "- transfer learning의 기본적인 방법은 중간에 hidden layer는 pretrained_model의 것을 이용하고 output layer를 내가 원하는 방향으로 만들어서 training 하는 것이다. 따라서, self.fc1, self.type_clf, self.softmax 등등 다양한 레이어들을 추가해줬다. 이때 self.fc1에는 nn.Linear(768, 32)를 저장해줬는데, 이는 in_feature로 768, out_feature로는 32를 내보낸다는 뜻이다. 일반적으로 알고 있는 dense layer의 역할을 한다. 그 다음으로는 self.relu에 nn.ReLU()를 저장해서 activation function으로 사용해줬다. 그 다음으로는 multilabel classification 문제이기 때문에 각 label마다 nn.Linear(32, # of types)으로 레이어를 만들어줬다. 이때 # of types만큼의 out_feature가 필요한 이유는 types들을 one-hot encoding을 해줬기 때문이다. 그 다음으로는 classification에 많이 사용되는 nn.Softmax(dim=1)을 넣어줬다. softmax에서 나온 값들의 합은 1로써 어느 type에 해당되는지 확률들을 리턴해준다. 이때 합해져야되는 값들이 dim=1에 있기때문에 dim=1이라는 파라미터를 넣어주었다.\n",
    "\n",
    "\\__forward__()\n",
    "- 그 다음으로 꼭 작성해줘야 하는 function은 forward다. (backward는 필요없음) 여기서는 위에서 작성한 레이어들을 어느 순서로 지나칠지 순서를 정해주는 단계이다. 우선, pretrained_model을 지나고 나온 output을 fc1과 relu에 넘겨주고 그 다음으로는 각 label의 clf-softmax 페어를 지나쳐준다. 그리고 나온 4개의 output을 리턴해주면 된다. \n",
    "- multilabel이기 때문에 4개의 값을 리턴해주는거지 단순하게 binary 또는 multiclassification이면 보통 1개의 output만을 리턴해주면 된다.\n",
    "- 아래 코드에 써있듯이 input_ids는 토큰에 해당되는 ids들, attention_mask는 어느 토큰에 집중해야되는지 알려주는 역할을 한다. 이는 왜 필요하나 하면 padding 단계에서 추가된 padding token에 대한 접근을 막기위해 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.klue = base_model # from transformers package\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.type_clf = nn.Linear(32,4)\n",
    "        self.polarity_clf = nn.Linear(32,3)\n",
    "        self.tense_clf = nn.Linear(32,3)\n",
    "        self.certainty_clf = nn.Linear(32,2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # input_ids : token's id / attention_mask : make a model to focus on which token\n",
    "        klue_out = self.klue(input_ids= input_ids, attention_mask = attention_mask)[0][:,0]\n",
    "\n",
    "        x = self.fc1(klue_out)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        type_output = self.type_clf(x)\n",
    "        print('1.',type_output.shape)\n",
    "        type_output = self.softmax(type_output)\n",
    "        print('2.',type_output.shape)\n",
    "        polarity_output = self.polarity_clf(x)\n",
    "        polarity_output = self.softmax(polarity_output)\n",
    "        tense_output = self.tense_clf(x)\n",
    "        tense_output = self.softmax(tense_output)\n",
    "        certainty_output = self.certainty_clf(x)\n",
    "        certainty_output = self.softmax(certainty_output)\n",
    "        \n",
    "        return type_output, polarity_output, tense_output, certainty_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로는! training 단계이다.\n",
    "\n",
    "우선 val_loss를 기준으로 early_stop을 할건지 말건지 정하기 때문에 best_val_loss를 설정해주었고, crossentropyloss를 이용할건데 작아질수록 좋은 값이기 때문에 최초값은 높은 값으로 설정해주었다. \n",
    "\n",
    "그 다음으로는 criterion인데 이는 loss function이다. 4개의 다른 label들이 있기 때문에 dictionary에 4개를 넣어주었다. 나중 단계에서 criterion에 있는 CrossEntropyLoss를 통해서 true값과 pred값의 차이를 구하고 어떤 방향으로 weights를 조정해야되는지 정한다.\n",
    "\n",
    "optimizer는 어떤 방식으로 최적화를 한걸지 정해주는 변수인데, 일반적으로 많이 쓰이는 Adam을 써줬다. Adam 안에는 모델의 파라미터(model.parameters())와 learning_rate를 넣어주었다. 위에서 언급했듯이 이때 learning_rate가 큰지 작은지에 따라 training 속도가 결정난다. 그 다음으로는 모델을 gpu로 보내주었다. 이 코드가 있어야 gpu를 사용해서 training 한다.\n",
    "- mac m칩 유저의 경우 “PYTORCH_ENABLE_MPS_FALLBACK=1”를 설정해줘야 mps가 안되는 코드는 cpu로 계산을 해준다. (2022/12/16 cumsum은 mps로 계산이 안됨)\n",
    "\n",
    "그리고 주어진 epochs만큰 for loop을 돌리는데 그 밑에 있는 total_acc_train은 total_f1_train으로 바뀌어야 맞다. 이 부분은 중간에 f1 계산하는 코드 넣는거를 까먹고 못하고 코드를 그대로 돌려서 남은 것이니 만약 이 코드 그대로 돌린다고 하면 바꾸어주길 바란다. 그 밑에 total_loss_train은 epoch별로 loss 값이 어땠는지 기록해주기 위해 만든 변수다.\n",
    "\n",
    "그 다음으로는 model.train()이 있는데 이는 model을 training 모드로 만들어주는거다. 이렇게 해야 weight들이 업데이트된다. 이와 반대로 나중에 val이나 test set을 모델에 넘겨줄때는 model.eval()을 불러줘야한다. 이래야 weights들이 업데이트 되지 않는다.\n",
    "\n",
    "그 다음으로는 train_dataloader를 for loop으로 돌려주는데 뒤에 나오겠지만 dataloader는 지정해준 batch_size만큼 item의 x와 y를 넘겨준다. 이때 쓰이는 것이 위에서 만들어준 SentenceTypeDataset의 getitem()이다. 따라서, 5개의 변수 (train_input, type_label, polarity_label, tense_label, certainty_label)로 받아야한다. 그 다음으로는 train_input에 있는 attention_mask와 input_ids와 label들을 device로 넘겨준다.\n",
    "\n",
    "그리고 training을 시작하기 전에 optimizer.grad()를 설정해줘서 매 epoch마다 전에 썼던 값들을 기억하는 것이 아니라 0 베이스에서 시작하게 해준다. epoch를 통한 값들의 정확한 업데이트를 위해서는 꼭 필요한 코드다.\n",
    "\n",
    "그리고 나서 model에 input_ids와 attention_mask를 넣어서 얻은 4개의 값들을 저장해준다. 이때 이 값들은 각 label마다 one-hot encoding된 컬럼에 해당될 확률들이다. 바로 다음에 이 값들은 criterion에 있는 CrossEntropyLoss()로 들어가서 실제와 얼마나 유사한지 계산되고 그 계산된 값을 total_loss_train에 저장해준다.\n",
    "\n",
    "그 다음으로는 계산된 loss 값을 바탕으로 backpropagation(loss.backward()과 optimizer.step()을 통해서)을 진행하여 weights들을 업데이트해준다.\n",
    "\n",
    "이렇게 training data를 다 거쳤다면 그 다음은 validation data 차례다. 우선 with torch.no_grad()과 model.eval()을 불러주어서 weights들을 업데이트하는게 아니라는 것을 선언해준다. 그 후에는 training data에서 했던 방식이랑 다 같지만 optimizer.zero_grad(), loss.backward(), optimier.step()만 빠진다. weights들을 업데이트하지 않기 때문.\n",
    "\n",
    "그 다음으로는 지금까지 저장한 loss와 metric을 프린트해주고, val_loss가 좋아졌는지 여부에 따라서 모델을 저장할 것인지 early stop 할 것인지 정해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentence_train(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm):\n",
    "    best_val_loss = 99999999999999 # setting max (act as infinity)\n",
    "    early_stopping_threshold_count = 0\n",
    "\n",
    "    criterion = {\n",
    "        'type' : nn.CrossEntropyLoss().to(device),\n",
    "        'polarity' : nn.CrossEntropyLoss().to(device),\n",
    "        'tense' : nn.CrossEntropyLoss().to(device),\n",
    "        'certainty' : nn.CrossEntropyLoss().to(device)\n",
    "    }\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_f1_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        model.train() # sets into the training mode\n",
    "        \n",
    "        for train_input, type_label, polarity_label, tense_label, certainty_label in tqdm(train_dataloader):\n",
    "            attention_mask = train_input['attention_mask'].to(device)\n",
    "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
    "#             type_label = type_label.to(device)\n",
    "            type_label = type_label.long().to(device)\n",
    "#             polarity_label = polarity_label.to(device)\n",
    "            polarity_label = polarity_label.long().to(device)\n",
    "#             tense_label = tense_label.to(device)\n",
    "            tense_label = tense_label.long().to(device)\n",
    "#             certainty_label = certainty_label.to(device)\n",
    "            certainty_label = certainty_label.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            type_output, polarity_output, tense_output, certainty_output = model(input_ids, attention_mask) # from the forward function\n",
    "            print(type_output.shape,type_label.shape)\n",
    "\n",
    "            loss = 0.25*criterion['type'](type_output, type_label) + \\\n",
    "                   0.25*criterion['polarity'](polarity_output, polarity_label) + \\\n",
    "                   0.25*criterion['tense'](tense_output, tense_label) + \\\n",
    "                   0.25*criterion['certainty'](certainty_output, certainty_label)\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        with torch.no_grad(): # since we should not change gradient for validation \n",
    "            total_f1_val = 0\n",
    "            total_loss_val = 0\n",
    "            \n",
    "            model.eval() # deactivate training\n",
    "            \n",
    "            # same process as the above\n",
    "            for val_input, vtype_label, vpolarity_label, vtense_label, vcertainty_label in tqdm(val_dataloader):\n",
    "                attention_mask = val_input['attention_mask'].to(device)\n",
    "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                vtype_label = vtype_label.to(device)\n",
    "                vpolarity_label = vpolarity_label.to(device)\n",
    "                vtense_label = vtense_label.to(device)\n",
    "                vcertainty_label = vcertainty_label.to(device)\n",
    "                \n",
    "                vtype_output, vpolarity_output, vtense_output, vcertainty_output = model(input_ids, attention_mask) # from the forward function\n",
    "\n",
    "                loss = 0.25*criterion['type'](vtype_output, vtype_label) + \\\n",
    "                        0.25*criterion['polarity'](vpolarity_output, vpolarity_label) + \\\n",
    "                        0.25*criterion['tense'](vtense_output, vtense_label) + \\\n",
    "                        0.25*criterion['certainty'](vcertainty_output, vcertainty_label)\n",
    "\n",
    "                total_loss_val += loss.item()\n",
    "\n",
    "            \n",
    "            print(f'Epochs: {epoch + 1} '\n",
    "                  f'| Train Loss: {total_loss_train / len(train_dataloader): .3f} '\n",
    "                  f'| Train Accuracy: {total_f1_train / (len(train_dataloader.dataset)): .3f} '\n",
    "                  f'| Val Loss: {total_loss_val / len(val_dataloader): .3f} '\n",
    "                  f'| Val Accuracy: {total_f1_val / len(val_dataloader.dataset): .3f}')\n",
    "            \n",
    "            if best_val_loss > total_loss_val:\n",
    "                best_val_loss = total_loss_val # saving only the best one\n",
    "                torch.save(model, f\"model/{model_nm}.pt\")\n",
    "                print(\"Saved model\")\n",
    "                early_stopping_threshold_count = 0\n",
    "            else:\n",
    "                early_stopping_threshold_count += 1 # checking how many epochs have passed that val_loss didn't increase\n",
    "                \n",
    "            if early_stopping_threshold_count >= 3: # ==> patience=1\n",
    "                print(\"Early stopping\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 class, function들은 다 적었으니 이제 dataset들을 준비할 차례다.\n",
    "\n",
    "우선 train에서 label을 제외한 나머지 컬럼들만 킵해주고 그중에서도 유형,극성,시제,확실성을 pd.get_dummies로 one-hot encoding해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>문장</th>\n",
       "      <th>유형_대화형</th>\n",
       "      <th>유형_사실형</th>\n",
       "      <th>유형_예측형</th>\n",
       "      <th>유형_추론형</th>\n",
       "      <th>극성_긍정</th>\n",
       "      <th>극성_미정</th>\n",
       "      <th>극성_부정</th>\n",
       "      <th>시제_과거</th>\n",
       "      <th>시제_미래</th>\n",
       "      <th>시제_현재</th>\n",
       "      <th>확실성_불확실</th>\n",
       "      <th>확실성_확실</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>화양정(서울 성동구 살곶이목장 내에 있던 정자) 앞에 목책을 세우고 각 읍에 예치했...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A씨는 지난 2020년 11월 10일 오전 1시 10분쯤 인천시 미추홀구 자신의 모...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>제조원가는 물론 판매관리비와 이익까지 과세표준에 포함되는 국산맥주와 달리 수입맥주는...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>똑똑선물샵은 선물하는 대상과 의도에 맞는 적절한 상품을 AI가 큐레이션하는 서비스다.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B군의 머리카락이 비교적 짧았지만 마른 체형인데다 여장을 한 상황에서 성별을 구별하...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>20일 출시되는 일본산 게임 ＇우마무스메 프리티더비＇와 23일 한국산 ＇미르M＇, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13228</th>\n",
       "      <td>여기에 설상가상 케인은 4주 이상 결장이 예상돼 손흥민의 복귀는 토트넘에게는 반가운...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>단한 번도 경험해보지 못한 선거를 경험할 판이다.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>재고를 팔아 매출채권을 찍고 다시 현금이 유입되는 선순환이 원활히 작동해야 하는데,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13231</th>\n",
       "      <td>감이나 배와 게를 함께 먹지 말아야 한다.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13232 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      문장  유형_대화형  유형_사실형  \\\n",
       "0      화양정(서울 성동구 살곶이목장 내에 있던 정자) 앞에 목책을 세우고 각 읍에 예치했...       0       1   \n",
       "1      A씨는 지난 2020년 11월 10일 오전 1시 10분쯤 인천시 미추홀구 자신의 모...       0       1   \n",
       "2      제조원가는 물론 판매관리비와 이익까지 과세표준에 포함되는 국산맥주와 달리 수입맥주는...       0       1   \n",
       "3        똑똑선물샵은 선물하는 대상과 의도에 맞는 적절한 상품을 AI가 큐레이션하는 서비스다.       0       1   \n",
       "4      B군의 머리카락이 비교적 짧았지만 마른 체형인데다 여장을 한 상황에서 성별을 구별하...       0       0   \n",
       "...                                                  ...     ...     ...   \n",
       "13227  20일 출시되는 일본산 게임 ＇우마무스메 프리티더비＇와 23일 한국산 ＇미르M＇, ...       0       0   \n",
       "13228  여기에 설상가상 케인은 4주 이상 결장이 예상돼 손흥민의 복귀는 토트넘에게는 반가운...       0       0   \n",
       "13229                        단한 번도 경험해보지 못한 선거를 경험할 판이다.       0       0   \n",
       "13230  재고를 팔아 매출채권을 찍고 다시 현금이 유입되는 선순환이 원활히 작동해야 하는데,...       0       1   \n",
       "13231                            감이나 배와 게를 함께 먹지 말아야 한다.       0       0   \n",
       "\n",
       "       유형_예측형  유형_추론형  극성_긍정  극성_미정  극성_부정  시제_과거  시제_미래  시제_현재  확실성_불확실  \\\n",
       "0           0       0      1      0      0      1      0      0        0   \n",
       "1           0       0      1      0      0      1      0      0        0   \n",
       "2           0       0      1      0      0      1      0      0        0   \n",
       "3           0       0      1      0      0      0      0      1        0   \n",
       "4           0       1      1      0      0      1      0      0        0   \n",
       "...       ...     ...    ...    ...    ...    ...    ...    ...      ...   \n",
       "13227       1       0      1      0      0      0      0      1        0   \n",
       "13228       0       1      1      0      0      0      0      1        0   \n",
       "13229       0       1      1      0      0      0      0      1        1   \n",
       "13230       0       0      1      0      0      1      0      0        0   \n",
       "13231       0       1      0      0      1      0      0      1        0   \n",
       "\n",
       "       확실성_확실  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "13227       1  \n",
       "13228       1  \n",
       "13229       0  \n",
       "13230       1  \n",
       "13231       1  \n",
       "\n",
       "[13232 rows x 13 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tmp = train[['문장', '유형', '극성', '시제', '확실성']]\n",
    "train_tmp = pd.get_dummies(train_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
    "train_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음으로는 각 label별로 뽑아서 train_labels에 dictionary형태로 저장해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type = train_tmp.iloc[:,1:5].values.tolist()\n",
    "train_polarity = train_tmp.iloc[:,5:8].values.tolist()\n",
    "train_tense = train_tmp.iloc[:,8:11].values.tolist()\n",
    "train_certainty = train_tmp.iloc[:,11:13].values.tolist()\n",
    "train_labels = {\n",
    "    'type': train_type,\n",
    "    'polarity': train_polarity,\n",
    "    'tense': train_tense,\n",
    "    'certainty': train_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "똑같은 방식으로 validation data도 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tmp = val[['문장', '유형', '극성', '시제', '확실성']]\n",
    "val_tmp = pd.get_dummies(val_tmp, columns=['유형', '극성', '시제', '확실성'])\n",
    "\n",
    "val_type = val_tmp.iloc[:,1:5].values.tolist()\n",
    "val_polarity = val_tmp.iloc[:,5:8].values.tolist()\n",
    "val_tense = val_tmp.iloc[:,8:11].values.tolist()\n",
    "val_certainty = val_tmp.iloc[:,11:13].values.tolist()\n",
    "val_labels = {\n",
    "    'type': val_type,\n",
    "    'polarity': val_polarity,\n",
    "    'tense': val_tense,\n",
    "    'certainty': val_certainty\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, val set가 준비되었다면 위에서 만든 SetenceTypeDataset에 dataframe, tokenizer, labels들을 넣어주고 SentenceTypeDataset, batch_size는 필수적으로 값을 정해서 DataLoader에 넣어준다. 위에서 잠깐 언급했듯이 DataLoader는 지정된 batch_size만큼 item들을 모델에 넘겨주어서 training 할 수 있게 해준다. \n",
    "\n",
    "여기서 shuffle는 item들을 랜덤하게 고른다는 의미고 num_workers는 설명을 봐도 잘 모르겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(SentenceTypeDataset(train_tmp, tokenizer, train_labels), batch_size=CFG['BATCH_SIZE'], \n",
    "                              shuffle=True, num_workers=0) # num_workers: how many subprocesses to use for data loading\n",
    "val_dataloader = DataLoader(SentenceTypeDataset(val_tmp, tokenizer, val_labels), batch_size=CFG['BATCH_SIZE'], num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음으로는 base_model (klue를 이용한 pretrained_model)을 기반으로해서 SentenceClassifier를 불러준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceClassifier(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 이제서야 training을 할 수 있는 상태에 온 것이다. \n",
    "\n",
    "위에서 만든 sentence_train function에 필요한 파라미터들을 보내주어서 training을 시작해준다.\n",
    "\n",
    "(위에서 말했듯이 f1을 계산 안하고 accuracy를 그대로 남겨주었기 때문에 accuracy는 계속 0이다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/414 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. torch.Size([32, 4])\n",
      "2. torch.Size([32, 4])\n",
      "torch.Size([32, 4]) torch.Size([32, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-bd6426753ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LEARNING_RATE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EPOCHS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kclue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-170-e1207f00798f>\u001b[0m in \u001b[0;36msentence_train\u001b[0;34m(model, train_dataloader, val_dataloader, learning_rate, epochs, model_nm)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                    \u001b[0;36m0.25\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polarity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolarity_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                    \u001b[0;36m0.25\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tense'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtense_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtense_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:15"
     ]
    }
   ],
   "source": [
    "sentence_train(model, train_dataloader, val_dataloader, CFG['LEARNING_RATE'], CFG['EPOCHS'], 'kclue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training이 끝났으면 test data를 이용해 예측을 해야되는데 이때 방법은 validation때와 비슷하다. 따라서, 설명은 생략하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_predictions(model, loader):\n",
    "\n",
    "    device = torch.device('mps')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    type_probs, polarity_probs, tense_probs, clarity_probs = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data_input, _, _, _, _ in tqdm(loader):\n",
    "            attention_mask = data_input['attention_mask'].to(device)\n",
    "            input_ids = data_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "\n",
    "            type_output, polarity_output, tense_output, clarity_output = model(input_ids, attention_mask)\n",
    "            type_probs.append(type_output)\n",
    "            polarity_probs.append(polarity_output)\n",
    "            tense_probs.append(tense_output)\n",
    "            clarity_probs.append(clarity_output)\n",
    "    \n",
    "    return torch.cat(type_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(polarity_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(tense_probs).cpu().detach().numpy(), \\\n",
    "            torch.cat(clarity_probs).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model/kclue.pt\")\n",
    "test_dataloader = DataLoader(SentenceTypeDataset(test, tokenizer), batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_pred_type, val_pred_polarity, val_pred_tense, val_pred_certainty = get_type_predictions(model, val_dataloader)\n",
    "\n",
    "#val_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in val_pred_type]]\n",
    "#val_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in val_pred_polarity]]\n",
    "#val_type = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in val_pred_tense]]\n",
    "#val_type = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in val_pred_certainty]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_type, test_pred_polarity, test_pred_tense, test_pred_certainty = get_type_predictions(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 잠깐 test_pred_tense가 어떻게 생겼는지 살펴보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_tense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에 보이는 것과 같이 tense에는 3개의 타입이 있으므로 3개의 컬럼들을 볼 수 있다. 그리고 각 컬럼에 해당될 확률이 어느정도인지 저장되어 있는 형태이다. 이때 같은 row에 위치한 값들을 더해보면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_pred_tense[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1인것을 알 수 있다. 위에 softmax에서 설명한 그대로이다.\n",
    "\n",
    "따라서, 이제 이 값들을 np.argmax()를 통해서 어느 인덱스에 최고 값이 있는지 알아보고 그 인덱스에 맞춰서 맞는 label로 변형해줘야 한다.\n",
    "그 후 저장하면 제출할 수 있는 파일이 만들어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_type = ['대화형' if i==0 else '사실형' if i==1 else '예측형' if i==2 else '추론형' for i in [np.argmax(p) for p in test_pred_type]]\n",
    "test_polarity = ['긍정' if i==0 else '미정' if i==1 else '부정' for i in [np.argmax(p) for p in test_pred_polarity]]\n",
    "test_tense = ['과거' if i==0 else '미래' if i==1 else '현재' for i in [np.argmax(p) for p in test_pred_tense]]\n",
    "test_certainty = ['불확실' if i==0 else '확실' for i in [np.argmax(p) for p in test_pred_certainty]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_sum = []\n",
    "for i in range(len(test_type)):\n",
    "    label_sum.append(f'{test_type[i]}-{test_polarity[i]}-{test_tense[i]}-{test_certainty[i]}')\n",
    "\n",
    "submission['label'] = label_sum\n",
    "submission.to_csv('submission/klue1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>TEST_7085</td>\n",
       "      <td>사실형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>TEST_7086</td>\n",
       "      <td>추론형-긍정-현재-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087</th>\n",
       "      <td>TEST_7087</td>\n",
       "      <td>사실형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>TEST_7088</td>\n",
       "      <td>추론형-긍정-미래-확실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>TEST_7089</td>\n",
       "      <td>사실형-긍정-과거-확실</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7090 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID         label\n",
       "0     TEST_0000  사실형-긍정-현재-확실\n",
       "1     TEST_0001  사실형-긍정-현재-확실\n",
       "2     TEST_0002  사실형-긍정-과거-확실\n",
       "3     TEST_0003  사실형-긍정-과거-확실\n",
       "4     TEST_0004  사실형-긍정-과거-확실\n",
       "...         ...           ...\n",
       "7085  TEST_7085  사실형-긍정-현재-확실\n",
       "7086  TEST_7086  추론형-긍정-현재-확실\n",
       "7087  TEST_7087  사실형-긍정-미래-확실\n",
       "7088  TEST_7088  추론형-긍정-미래-확실\n",
       "7089  TEST_7089  사실형-긍정-과거-확실\n",
       "\n",
       "[7090 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "궁금한 부분이나 조언이 있다면 댓글에 남겨주세요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1201aed7278f566d08684214e947d9aa97ba318061e22672851b23b6bee3a7a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
