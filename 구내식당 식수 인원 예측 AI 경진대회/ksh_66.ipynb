{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from konlpy.tag import Mecab\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 띄어쓰기 및 오타 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.at[1142, '중식메뉴'] = '쌀밥/곤드레밥/찰현미밥 된장찌개 돼지고추장불고기 버섯잡채 삼색물만두무침 겉절이김치/양념장 견과류샐러드*요거트D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식메뉴'] = train['중식메뉴'].str.replace('삽겹', '삼겹')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['일자'] = pd.to_datetime(train['일자'])\n",
    "test['일자'] = pd.to_datetime(test['일자'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['요일'] = train['일자'].dt.day_name().str[:2].map({'Mo' : 5, 'Tu' : 4, 'We' : 3, 'Th' : 2, 'Fr' : 1})\n",
    "test['요일'] = test['일자'].dt.day_name().str[:2].map({'Mo' : 5, 'Tu' : 4, 'We' : 3, 'Th' : 2, 'Fr' : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train['일자'].dt.month\n",
    "test['month'] = test['일자'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['corona'] = [1 if x > 0 else 0 for x in train['현본사소속재택근무자수']]\n",
    "test['corona'] = [1 if x > 0 else 0 for x in test['현본사소속재택근무자수']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다음 출근날까지의 일수 차이\n",
    "- ex) 오늘이 12월 31일 목요일인 경우 다음 출근날은 1월 4일이기 때문에 값이 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['shift_1day'] = train.일자.shift(-1)\n",
    "test['shift_1day'] = test.일자.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.at[1204, 'shift_1day'] = datetime(2021,1,27)\n",
    "test.at[49, 'shift_1day'] = datetime(2021,4,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day_gap'] = (train.shift_1day - train.일자).astype(str)\n",
    "test['day_gap'] = (test.shift_1day - test.일자).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.at[0, 'day_gap'] = '1 days'\n",
    "test.at[0, 'day_gap'] = '1 days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holiday_score(x) :\n",
    "    \n",
    "    s = int(re.sub(r'[^0-9]', '', x))\n",
    "    if s == 1 :\n",
    "        return 0\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day_gap'] = train.day_gap.apply(get_holiday_score)\n",
    "test['day_gap'] = test.day_gap.apply(get_holiday_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['야근요일'] = train.요일.apply(lambda x : 1 if (x == 1) or (x == 3) else 0)\n",
    "test['야근요일'] = test.요일.apply(lambda x : 1 if (x == 1) or (x == 3) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식메뉴'] = train['중식메뉴'].str.split(' ')\n",
    "train['석식메뉴'] = train['석식메뉴'].str.split(' ')\n",
    "\n",
    "test['중식메뉴'] = test['중식메뉴'].str.split(' ')\n",
    "test['석식메뉴'] = test['석식메뉴'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(data) :\n",
    "    tokens = []\n",
    "    for token in data :\n",
    "        s_list = []\n",
    "        for t in token :\n",
    "            if t.startswith('(N') :\n",
    "                s_list.append(t)\n",
    "            elif (t.startswith('(') == False) & (len(t) > 1) :\n",
    "                s_list.append(t)\n",
    "            else :\n",
    "                pass\n",
    "        tokens.append(s_list)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식_토큰'] = get_token(train['중식메뉴'])\n",
    "train['석식_토큰'] = get_token(train['석식메뉴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['중식_토큰'] = get_token(test['중식메뉴'])\n",
    "test['석식_토큰'] = get_token(test['석식메뉴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식메뉴수'] = train.중식_토큰.apply(len)\n",
    "train['석식메뉴수'] = train.석식_토큰.apply(len)\n",
    "\n",
    "test['중식메뉴수'] = test.중식_토큰.apply(len)\n",
    "test['석식메뉴수'] = test.석식_토큰.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 식재료\n",
    "- 중식에만 처리함 -> 메뉴가 중식에서 더 중요할 것으로 판단했기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredient(data) :\n",
    "    \n",
    "    ing_df = pd.DataFrame(np.zeros((data.shape[0], 7)), columns = ['해산물', '소', '돼지', '닭', '오리', '채소', '재료_기타'])\n",
    "\n",
    "    for t in range(data.shape[0]) :\n",
    "        token = data.중식_토큰.str[2][t]\n",
    "        if '연어' in token or'골뱅이' in token or'열기' in token or'조기' in token or'탕수어' in token or'양장피' in token or'홍어' in token or'명태' in token or'적어' in token or'장어' in token or'동태' in token or'산슬' in token or'코다리' in token or'가자미' in token or'해물' in token or'생선' in token or'새우' in token or'꽁치' in token or'갈치' in token or'임연수' in token or'삼치' in token or'고등어' in token or'굴비' in token or'오징어' in token or'쭈꾸미' in token or'주꾸미' in token or'낙지' in token or'문어' in token :\n",
    "            ing_df.at[t, '해산물'] = 1\n",
    "        elif '왕갈비' in token or'소갈비' in token or'장조림' in token or'불고기' in token or'차돌' in token or'육전' in token or'너비아니' in token or'떡갈비' in token or(token.startswith('소') & (token.startswith('소세') == False)) or '함박' in token or'쇠고기' in token or'소고기' in token or'쇠' in token :\n",
    "            ing_df.at[t, '소'] = 1\n",
    "        elif '궁보계정' in token or'삼계탕' in token or'윙' in token or'유린기' in token or'깐풍'in token or'닭' in token or'치킨' in token or'후라이드' in token :\n",
    "            ing_df.at[t, '돼지'] = 1\n",
    "        elif '폭립' in token or'오향장육' in token or'동파육' in token or'히레카츠' in token or'순대' in token or'미트볼' in token or'등갈비' in token or'소세지' in token or'목살' in token or'탕수육' in token or'제육' in token or'돈' in token or'돼지' in token or'두루치기' in token or'삼겹' in token or'보쌈' in token or'족발' in token :\n",
    "            ing_df.at[t, '닭'] = 1\n",
    "        elif '오리' in token :\n",
    "            ing_df.at[t, '오리'] = 1\n",
    "        elif token.endswith('두부') or '꼬치산적' in token or '고추' in token or'양파' in token or'부추' in token or'고구마' in token or'감자' in token or'깻잎' in token or'샐러드' in token or'시금치' in token or'야채' in token :\n",
    "            ing_df.at[t, '채소'] = 1\n",
    "        else :\n",
    "            ing_df.at[t, '재료_기타'] = 1\n",
    "            \n",
    "    return ing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, get_ingredient(train)], axis = 1)\n",
    "test = pd.concat([test, get_ingredient(test)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조리법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe(data, col) :\n",
    "    tm = col[:2]\n",
    "    cat = ['전', '무침','튀김', '찜', '볶음', '조림', '구이', '훈제', '조리_기타']\n",
    "    recipe_df = pd.DataFrame(np.zeros((data.shape[0], 9)), columns = [f'{tm}_{x}' for x in cat])\n",
    "\n",
    "    for t in range(data.shape[0]) :\n",
    "        try :\n",
    "            token = data[col][t]\n",
    "            if '고추잡채' in token or '궁보계정' in token or '산슬' in token or token.endswith('잡채') or '마파두부' in token or '두루치기' in token or '닭갈비' in token or token.endswith('볶음') or '볶음' in token :\n",
    "                recipe_df.at[t, f'{tm}_볶음'] = 1 \n",
    "            elif token.endswith('데리야끼') or token.endswith('립') or '함박' in token or '그라탕' in token or token.endswith('갈비') or '주물럭' in token or '스테이크' in token or token.endswith('구이') or '불고기' in token or '구이' in token :\n",
    "                recipe_df.at[t, f'{tm}_구이'] = 1\n",
    "            elif '전병' in token or token.endswith('전') :\n",
    "                recipe_df.at[t, f'{tm}_전'] = 1\n",
    "            elif token.endswith('김치말이') or token.endswith('만두') or '보쌈' in token or '수육' in token or token.endswith('찜') or '찜' in token :\n",
    "                recipe_df.at[t, f'{tm}_찜'] = 1\n",
    "            elif '파채' in token or token.endswith('무침') or token.endswith('샐러드') or '양장피' in token :\n",
    "                recipe_df.at[t, f'{tm}_무침'] = 1\n",
    "            elif '오향장육' in token or '동파육' in token or token.endswith('조림') :\n",
    "                recipe_df.at[t, f'{tm}_조림'] = 1\n",
    "            elif '통닭' in token or token.endswith('새우') or '강정' in token or '미트볼' in token or '프리타타' in token or '카츠' in token or '깐풍' in token or '고로케' in token or '유린기' in token or '탕수' in token or token.endswith('닭') or token.endswith('치킨') or token.endswith('튀김') or '너겟' in token or token.endswith('강정') or '가스' in token or '까스' in token or '핑거' in token or '텐더' in token or '커틀렛' in token or '커틀릿' in token :\n",
    "                recipe_df.at[t, f'{tm}_튀김'] = 1\n",
    "            elif '훈제' in token :\n",
    "                recipe_df.at[t, f'{tm}_훈제'] = 1\n",
    "            else :\n",
    "                recipe_df.at[t, f'{tm}_조리_기타'] = 1\n",
    "        except :\n",
    "            recipe_df.at[t, f'{tm}_조리_기타'] = 1\n",
    "    return recipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식_메인요리'] = train.중식_토큰.str[2]\n",
    "test['중식_메인요리'] = test.중식_토큰.str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['석식_메인요리'] = train.석식_토큰.str[2]\n",
    "test['석식_메인요리'] = test.석식_토큰.str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, get_recipe(train, '중식_메인요리')], axis = 1)\n",
    "test = pd.concat([test, get_recipe(test, '중식_메인요리')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, get_recipe(train, '석식_메인요리')], axis = 1)\n",
    "test = pd.concat([test, get_recipe(test, '석식_메인요리')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['출근'] = train['본사정원수']-(train['본사휴가자수']+train['본사출장자수']+train['현본사소속재택근무자수'])\n",
    "train['휴가비율'] = train['본사휴가자수']/train['본사정원수']\n",
    "train['출장비율'] = train['본사출장자수']/train['본사정원수']\n",
    "train['야근비율'] = train['본사시간외근무명령서승인건수']/train['출근']\n",
    "train['재택비율'] = train['현본사소속재택근무자수']/train['본사정원수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['출근'] = test['본사정원수']-(test['본사휴가자수']+test['본사출장자수']+test['현본사소속재택근무자수'])\n",
    "test['휴가비율'] = test['본사휴가자수']/test['본사정원수']\n",
    "test['출장비율'] = test['본사출장자수']/test['본사정원수']\n",
    "test['야근비율'] = test['본사시간외근무명령서승인건수']/test['출근']\n",
    "test['재택비율'] = test['현본사소속재택근무자수']/test['본사정원수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = train[['요일', '야근요일', '출근', 'day_gap', '휴가비율', '출장비율', '야근비율', 'month',  '중식메뉴수', '해산물', '소', '돼지', '닭', '오리', '채소', '재료_기타', '중식_전', '중식_무침', '중식_튀김', '중식_찜', \n",
    "       '중식_볶음', '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = test[X1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = train[['corona', '석식메뉴수', 'month', '야근요일', 'day_gap', '요일', '출근', '휴가비율', '출장비율', '야근비율', '재택비율', '석식_전', '석식_무침', \n",
    "       '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2 = test[X2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = train.중식계\n",
    "y2 = train.석식계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 15, random_state = 718, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostRegressor(iterations = 20000, learning_rate = 0.01, depth = 4, eval_metric = 'MAE', silent = True, loss_function = 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 165.7208086\ttest: 174.4951842\tbest: 174.4951842 (0)\ttotal: 62.1ms\tremaining: 20m 41s\n",
      "5000:\tlearn: 44.7818178\ttest: 61.9085747\tbest: 61.8818070 (4932)\ttotal: 5.61s\tremaining: 16.8s\n",
      "10000:\tlearn: 38.2252302\ttest: 61.4473138\tbest: 61.4084062 (9821)\ttotal: 10.3s\tremaining: 10.3s\n",
      "15000:\tlearn: 35.0579376\ttest: 61.4200779\tbest: 61.3247083 (13580)\ttotal: 14.9s\tremaining: 4.97s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 61.32470828\n",
      "bestIteration = 13580\n",
      "\n",
      "Shrink model to first 13581 iterations.\n",
      "FOLD MAE = 61.325879285875395\n",
      "0:\tlearn: 166.7712980\ttest: 162.5986410\tbest: 162.5986410 (0)\ttotal: 2.48ms\tremaining: 49.5s\n",
      "5000:\tlearn: 44.3015596\ttest: 73.9240744\tbest: 73.9210822 (4978)\ttotal: 4.68s\tremaining: 14s\n",
      "10000:\tlearn: 38.2208748\ttest: 73.6280890\tbest: 73.6024269 (8660)\ttotal: 9.4s\tremaining: 9.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 73.43427955\n",
      "bestIteration = 11274\n",
      "\n",
      "Shrink model to first 11275 iterations.\n",
      "FOLD MAE = 73.44116029175416\n",
      "0:\tlearn: 167.5675435\ttest: 150.2908632\tbest: 150.2908632 (0)\ttotal: 2.17ms\tremaining: 43.3s\n",
      "5000:\tlearn: 44.7227380\ttest: 74.5972176\tbest: 74.5828811 (4996)\ttotal: 5.62s\tremaining: 16.9s\n",
      "10000:\tlearn: 38.0116395\ttest: 73.6144847\tbest: 73.6086317 (9954)\ttotal: 10.6s\tremaining: 10.6s\n",
      "15000:\tlearn: 34.5494907\ttest: 73.3208481\tbest: 73.2497922 (14399)\ttotal: 16.3s\tremaining: 5.43s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 73.24979216\n",
      "bestIteration = 14399\n",
      "\n",
      "Shrink model to first 14400 iterations.\n",
      "FOLD MAE = 73.25400931096382\n",
      "0:\tlearn: 165.4556930\ttest: 178.2422212\tbest: 178.2422212 (0)\ttotal: 957us\tremaining: 19.1s\n",
      "5000:\tlearn: 44.7400031\ttest: 71.4169900\tbest: 71.4092342 (4951)\ttotal: 5.75s\tremaining: 17.3s\n",
      "10000:\tlearn: 38.1293262\ttest: 70.1272320\tbest: 70.1219623 (9929)\ttotal: 11.7s\tremaining: 11.7s\n",
      "15000:\tlearn: 34.5660624\ttest: 69.5591275\tbest: 69.5565705 (14521)\ttotal: 18.1s\tremaining: 6.04s\n",
      "19999:\tlearn: 32.1973893\ttest: 69.6201863\tbest: 69.4484143 (18275)\ttotal: 23.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 69.44841431\n",
      "bestIteration = 18275\n",
      "\n",
      "Shrink model to first 18276 iterations.\n",
      "FOLD MAE = 69.44873717484013\n",
      "0:\tlearn: 165.4903905\ttest: 178.1975299\tbest: 178.1975299 (0)\ttotal: 1.59ms\tremaining: 31.8s\n",
      "5000:\tlearn: 44.4355148\ttest: 59.3221024\tbest: 59.0446133 (3194)\ttotal: 4.6s\tremaining: 13.8s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 59.04461333\n",
      "bestIteration = 3194\n",
      "\n",
      "Shrink model to first 3195 iterations.\n",
      "FOLD MAE = 59.045004324345776\n",
      "0:\tlearn: 166.4326657\ttest: 164.6699990\tbest: 164.6699990 (0)\ttotal: 1.56ms\tremaining: 31.1s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 72.19559564\n",
      "bestIteration = 1575\n",
      "\n",
      "Shrink model to first 1576 iterations.\n",
      "FOLD MAE = 72.21113646820054\n",
      "0:\tlearn: 166.8690746\ttest: 158.4353740\tbest: 158.4353740 (0)\ttotal: 1.93ms\tremaining: 38.5s\n",
      "5000:\tlearn: 44.4424223\ttest: 66.9859394\tbest: 66.9494436 (4966)\ttotal: 5.49s\tremaining: 16.5s\n",
      "10000:\tlearn: 37.7448596\ttest: 65.7108187\tbest: 65.7108187 (10000)\ttotal: 11.5s\tremaining: 11.5s\n",
      "15000:\tlearn: 34.0591147\ttest: 65.0380276\tbest: 65.0321017 (14712)\ttotal: 16.3s\tremaining: 5.45s\n",
      "19999:\tlearn: 31.6859908\ttest: 64.7527562\tbest: 64.7433350 (19963)\ttotal: 21.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 64.74333505\n",
      "bestIteration = 19963\n",
      "\n",
      "Shrink model to first 19964 iterations.\n",
      "FOLD MAE = 64.74352050328369\n",
      "0:\tlearn: 165.7627457\ttest: 174.1919990\tbest: 174.1919990 (0)\ttotal: 1.87ms\tremaining: 37.5s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 68.96826999\n",
      "bestIteration = 2329\n",
      "\n",
      "Shrink model to first 2330 iterations.\n",
      "FOLD MAE = 68.97047851319005\n",
      "0:\tlearn: 167.1451368\ttest: 154.5411240\tbest: 154.5411240 (0)\ttotal: 1.78ms\tremaining: 35.5s\n",
      "5000:\tlearn: 44.0941941\ttest: 68.9662231\tbest: 68.9314967 (4974)\ttotal: 6.76s\tremaining: 20.3s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 68.82871343\n",
      "bestIteration = 5785\n",
      "\n",
      "Shrink model to first 5786 iterations.\n",
      "FOLD MAE = 68.83381798863209\n",
      "0:\tlearn: 166.3453679\ttest: 165.9062490\tbest: 165.9062490 (0)\ttotal: 1.19ms\tremaining: 23.9s\n",
      "5000:\tlearn: 44.3907223\ttest: 76.0130723\tbest: 75.9884322 (4367)\ttotal: 5.31s\tremaining: 15.9s\n",
      "10000:\tlearn: 38.2212343\ttest: 75.1329271\tbest: 75.0740639 (9785)\ttotal: 10s\tremaining: 10s\n",
      "15000:\tlearn: 34.9527403\ttest: 74.5769527\tbest: 74.5721508 (14991)\ttotal: 14.7s\tremaining: 4.89s\n",
      "19999:\tlearn: 32.6966922\ttest: 74.4480753\tbest: 74.4277465 (18351)\ttotal: 19.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 74.42774649\n",
      "bestIteration = 18351\n",
      "\n",
      "Shrink model to first 18352 iterations.\n",
      "FOLD MAE = 74.42816472233842\n",
      "0:\tlearn: 166.6481590\ttest: 161.8689990\tbest: 161.8689990 (0)\ttotal: 1.99ms\tremaining: 39.8s\n",
      "5000:\tlearn: 44.1370568\ttest: 74.1716524\tbest: 74.1523410 (4978)\ttotal: 5.96s\tremaining: 17.9s\n",
      "10000:\tlearn: 37.7920561\ttest: 73.8773987\tbest: 73.8671126 (9963)\ttotal: 11.4s\tremaining: 11.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 73.86711265\n",
      "bestIteration = 9963\n",
      "\n",
      "Shrink model to first 9964 iterations.\n",
      "FOLD MAE = 73.86860684644739\n",
      "0:\tlearn: 165.8163546\ttest: 174.8531240\tbest: 174.8531240 (0)\ttotal: 816us\tremaining: 16.3s\n",
      "5000:\tlearn: 44.6813751\ttest: 61.0737143\tbest: 61.0276365 (4522)\ttotal: 5.36s\tremaining: 16.1s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 60.80820691\n",
      "bestIteration = 7357\n",
      "\n",
      "Shrink model to first 7358 iterations.\n",
      "FOLD MAE = 60.810023060525324\n",
      "0:\tlearn: 166.0689235\ttest: 169.8798740\tbest: 169.8798740 (0)\ttotal: 1.61ms\tremaining: 32.2s\n",
      "5000:\tlearn: 44.1200435\ttest: 68.6075689\tbest: 68.5697896 (4787)\ttotal: 4.96s\tremaining: 14.9s\n",
      "10000:\tlearn: 37.4172579\ttest: 67.1965703\tbest: 67.1397400 (9741)\ttotal: 9.95s\tremaining: 9.95s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 67.13787822\n",
      "bestIteration = 11021\n",
      "\n",
      "Shrink model to first 11022 iterations.\n",
      "FOLD MAE = 67.1380187740863\n",
      "0:\tlearn: 166.4346835\ttest: 164.7612490\tbest: 164.7612490 (0)\ttotal: 675us\tremaining: 13.5s\n",
      "5000:\tlearn: 44.2959676\ttest: 74.5449945\tbest: 74.4885937 (4908)\ttotal: 5.67s\tremaining: 17s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 73.91428639\n",
      "bestIteration = 7371\n",
      "\n",
      "Shrink model to first 7372 iterations.\n",
      "FOLD MAE = 73.9143054118516\n",
      "0:\tlearn: 166.3479279\ttest: 166.7234990\tbest: 166.7234990 (0)\ttotal: 972us\tremaining: 19.5s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 60.65441998\n",
      "bestIteration = 1328\n",
      "\n",
      "Shrink model to first 1329 iterations.\n",
      "FOLD MAE = 60.66796634689831\n",
      "\n",
      "CatBoostRegressor MAE = 68.14005526821553\n"
     ]
    }
   ],
   "source": [
    "cb_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X1):\n",
    "    tr_x, val_x = X1.iloc[tr_idx], X1.iloc[val_idx]\n",
    "    tr_y, val_y = y1.iloc[tr_idx], y1.iloc[val_idx]\n",
    "    train_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    cb.fit(train_data, eval_set = val_data, early_stopping_rounds = 2000, use_best_model = True, verbose = 5000)\n",
    "    best = cb.best_iteration_\n",
    "    pred = cb.predict(val_x, ntree_end = best)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = cb.predict(target1, ntree_end = best) / 15\n",
    "    cb_pred_1 += sub_pred\n",
    "print(f'\\n{cb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 99.0269474\ttest: 82.1235793\tbest: 82.1235793 (0)\ttotal: 1.93ms\tremaining: 38.7s\n",
      "5000:\tlearn: 29.9611929\ttest: 41.2941278\tbest: 41.2782356 (4618)\ttotal: 5.36s\tremaining: 16.1s\n",
      "10000:\tlearn: 26.0294826\ttest: 40.8838317\tbest: 40.8610027 (9930)\ttotal: 10.4s\tremaining: 10.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 40.73218658\n",
      "bestIteration = 12930\n",
      "\n",
      "Shrink model to first 12931 iterations.\n",
      "FOLD MAE = 40.734237100833674\n",
      "0:\tlearn: 99.1316182\ttest: 80.7050607\tbest: 80.7050607 (0)\ttotal: 1.82ms\tremaining: 36.4s\n",
      "5000:\tlearn: 29.2048574\ttest: 55.9635529\tbest: 55.9380499 (4861)\ttotal: 5.78s\tremaining: 17.3s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 55.69152869\n",
      "bestIteration = 6972\n",
      "\n",
      "Shrink model to first 6973 iterations.\n",
      "FOLD MAE = 55.693782736123964\n",
      "0:\tlearn: 97.9807641\ttest: 95.7135793\tbest: 95.7135793 (0)\ttotal: 1.73ms\tremaining: 34.6s\n",
      "5000:\tlearn: 29.9661490\ttest: 43.8533080\tbest: 43.8183328 (4000)\ttotal: 5.77s\tremaining: 17.3s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 43.81833281\n",
      "bestIteration = 4000\n",
      "\n",
      "Shrink model to first 4001 iterations.\n",
      "FOLD MAE = 43.81847416008471\n",
      "0:\tlearn: 97.2503193\ttest: 106.4114805\tbest: 106.4114805 (0)\ttotal: 1.32ms\tremaining: 26.4s\n",
      "5000:\tlearn: 29.2829716\ttest: 48.6531338\tbest: 48.6420856 (4852)\ttotal: 5.8s\tremaining: 17.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 48.55078182\n",
      "bestIteration = 5449\n",
      "\n",
      "Shrink model to first 5450 iterations.\n",
      "FOLD MAE = 48.56105595273324\n",
      "0:\tlearn: 97.9254616\ttest: 96.9072830\tbest: 96.9072830 (0)\ttotal: 1.6ms\tremaining: 32.1s\n",
      "5000:\tlearn: 29.7755595\ttest: 40.9053730\tbest: 40.9045719 (4994)\ttotal: 4.97s\tremaining: 14.9s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 40.68681248\n",
      "bestIteration = 6055\n",
      "\n",
      "Shrink model to first 6056 iterations.\n",
      "FOLD MAE = 40.687034835644056\n",
      "0:\tlearn: 96.6489501\ttest: 114.9941240\tbest: 114.9941240 (0)\ttotal: 1.39ms\tremaining: 27.8s\n",
      "5000:\tlearn: 29.9149936\ttest: 39.6928561\tbest: 39.6145600 (4764)\ttotal: 5.63s\tremaining: 16.9s\n",
      "10000:\tlearn: 25.6742804\ttest: 39.1496064\tbest: 39.1394826 (9883)\ttotal: 11.2s\tremaining: 11.2s\n",
      "15000:\tlearn: 23.3712987\ttest: 38.8058028\tbest: 38.7861137 (14971)\ttotal: 16.5s\tremaining: 5.5s\n",
      "19999:\tlearn: 21.8720421\ttest: 38.5076178\tbest: 38.4681175 (18159)\ttotal: 22.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 38.46811754\n",
      "bestIteration = 18159\n",
      "\n",
      "Shrink model to first 18160 iterations.\n",
      "FOLD MAE = 38.46812755239758\n",
      "0:\tlearn: 99.0211279\ttest: 81.7268740\tbest: 81.7268740 (0)\ttotal: 1.1ms\tremaining: 22s\n",
      "5000:\tlearn: 29.9462905\ttest: 41.3362296\tbest: 41.2455382 (4866)\ttotal: 5.24s\tremaining: 15.7s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 41.24553824\n",
      "bestIteration = 4866\n",
      "\n",
      "Shrink model to first 4867 iterations.\n",
      "FOLD MAE = 41.247552445864\n",
      "0:\tlearn: 97.6858212\ttest: 100.2473740\tbest: 100.2473740 (0)\ttotal: 725us\tremaining: 14.5s\n",
      "5000:\tlearn: 30.2407692\ttest: 37.9117371\tbest: 37.9077198 (4449)\ttotal: 5.31s\tremaining: 15.9s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 37.89926049\n",
      "bestIteration = 5035\n",
      "\n",
      "Shrink model to first 5036 iterations.\n",
      "FOLD MAE = 37.89958993783053\n",
      "0:\tlearn: 97.5656523\ttest: 101.6778740\tbest: 101.6778740 (0)\ttotal: 1.31ms\tremaining: 26.3s\n",
      "5000:\tlearn: 29.9099428\ttest: 35.3600070\tbest: 35.2981817 (4787)\ttotal: 5.84s\tremaining: 17.5s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 35.10249116\n",
      "bestIteration = 7675\n",
      "\n",
      "Shrink model to first 7676 iterations.\n",
      "FOLD MAE = 35.10337829912802\n",
      "0:\tlearn: 98.1231546\ttest: 94.2526240\tbest: 94.2526240 (0)\ttotal: 1.27ms\tremaining: 25.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 55.46845858\n",
      "bestIteration = 2962\n",
      "\n",
      "Shrink model to first 2963 iterations.\n",
      "FOLD MAE = 55.47460470572097\n",
      "0:\tlearn: 97.4935190\ttest: 102.8896240\tbest: 102.8896240 (0)\ttotal: 724us\tremaining: 14.5s\n",
      "5000:\tlearn: 29.2080824\ttest: 49.0159199\tbest: 49.0084972 (4985)\ttotal: 4.87s\tremaining: 14.6s\n",
      "10000:\tlearn: 24.9802525\ttest: 48.7781431\tbest: 48.7603686 (9770)\ttotal: 10.4s\tremaining: 10.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 48.73037993\n",
      "bestIteration = 11601\n",
      "\n",
      "Shrink model to first 11602 iterations.\n",
      "FOLD MAE = 48.732675629088526\n",
      "0:\tlearn: 96.6946390\ttest: 114.0312490\tbest: 114.0312490 (0)\ttotal: 1.31ms\tremaining: 26.1s\n",
      "5000:\tlearn: 29.6182705\ttest: 45.7707474\tbest: 45.6233286 (3904)\ttotal: 5.46s\tremaining: 16.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 45.60251848\n",
      "bestIteration = 5895\n",
      "\n",
      "Shrink model to first 5896 iterations.\n",
      "FOLD MAE = 45.60825198850498\n",
      "0:\tlearn: 97.3590301\ttest: 104.4489990\tbest: 104.4489990 (0)\ttotal: 1.32ms\tremaining: 26.3s\n",
      "5000:\tlearn: 29.7349610\ttest: 49.7517662\tbest: 49.7288071 (4984)\ttotal: 5.61s\tremaining: 16.8s\n",
      "10000:\tlearn: 25.5366497\ttest: 48.9319226\tbest: 48.9256055 (9952)\ttotal: 11.2s\tremaining: 11.2s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 48.85807527\n",
      "bestIteration = 10601\n",
      "\n",
      "Shrink model to first 10602 iterations.\n",
      "FOLD MAE = 48.85849588401657\n",
      "0:\tlearn: 98.7323901\ttest: 85.3723740\tbest: 85.3723740 (0)\ttotal: 1.42ms\tremaining: 28.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 49.23395509\n",
      "bestIteration = 2639\n",
      "\n",
      "Shrink model to first 2640 iterations.\n",
      "FOLD MAE = 49.23448896455727\n",
      "0:\tlearn: 97.1001768\ttest: 108.3168740\tbest: 108.3168740 (0)\ttotal: 1.92ms\tremaining: 38.4s\n",
      "5000:\tlearn: 30.1639453\ttest: 43.4518490\tbest: 43.4398276 (4981)\ttotal: 5.65s\tremaining: 16.9s\n",
      "10000:\tlearn: 26.0803665\ttest: 42.4882093\tbest: 42.4797307 (9950)\ttotal: 10.8s\tremaining: 10.8s\n",
      "15000:\tlearn: 23.8664801\ttest: 41.6126666\tbest: 41.5879812 (14602)\ttotal: 16.5s\tremaining: 5.51s\n",
      "19999:\tlearn: 22.2281418\ttest: 41.4114452\tbest: 41.3722459 (18905)\ttotal: 21.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 41.37224586\n",
      "bestIteration = 18905\n",
      "\n",
      "Shrink model to first 18906 iterations.\n",
      "FOLD MAE = 41.37231341706795\n",
      "\n",
      "CatBoostRegressor MAE = 44.7662709073064\n"
     ]
    }
   ],
   "source": [
    "cb_pred_2 = np.zeros((target2.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    train_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    cb.fit(train_data, eval_set = val_data, early_stopping_rounds = 2000, use_best_model = True, verbose = 5000)\n",
    "    best = cb.best_iteration_\n",
    "    pred = cb.predict(val_x, ntree_end = best)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = cb.predict(target2, ntree_end = best) / 15\n",
    "    cb_pred_2 += sub_pred\n",
    "print(f'\\n{cb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb = NGBRegressor(n_estimators = 15000, verbose = 0, random_state = 607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD MAE = 68.93021314897271\n",
      "FOLD MAE = 53.653937044849705\n",
      "FOLD MAE = 46.80557565007274\n",
      "FOLD MAE = 34.015911415767384\n",
      "FOLD MAE = 37.20199168499946\n",
      "FOLD MAE = 43.273489971316806\n",
      "FOLD MAE = 36.701970631269454\n",
      "FOLD MAE = 34.67354770644964\n",
      "FOLD MAE = 40.711893648589694\n",
      "FOLD MAE = 33.73674663410894\n",
      "FOLD MAE = 38.51425002765768\n",
      "FOLD MAE = 27.956151443367055\n",
      "FOLD MAE = 26.57288686138337\n",
      "FOLD MAE = 29.503053690826004\n",
      "FOLD MAE = 27.322885552213812\n",
      "\n",
      "NGBRegressor MAE = 38.63830034078964\n"
     ]
    }
   ],
   "source": [
    "ngb_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X1):\n",
    "    tr_x, val_x = X1.iloc[tr_idx], X1.iloc[val_idx]\n",
    "    tr_y, val_y = y1.iloc[tr_idx], y1.iloc[val_idx]\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 2000)\n",
    "    pred = ngb.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = ngb.predict(target1) / 15\n",
    "    ngb_pred_1 += sub_pred\n",
    "print(f'\\n{ngb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb = NGBRegressor(n_estimators = 15000, verbose = 0, random_state = 607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD MAE = 44.171664919086936\n",
      "FOLD MAE = 32.868913088772295\n",
      "FOLD MAE = 25.220459787217816\n",
      "FOLD MAE = 21.960386570669062\n",
      "FOLD MAE = 20.040524201800302\n",
      "FOLD MAE = 18.935727713350282\n",
      "FOLD MAE = 18.9116412699365\n",
      "FOLD MAE = 16.29463434135136\n",
      "FOLD MAE = 16.74260426529482\n",
      "FOLD MAE = 20.35581551304555\n",
      "FOLD MAE = 18.07844819538711\n",
      "FOLD MAE = 17.947413300843102\n",
      "FOLD MAE = 17.985124950816843\n",
      "FOLD MAE = 16.079115696458693\n",
      "FOLD MAE = 14.079807129401638\n",
      "\n",
      "NGBRegressor MAE = 21.31148539622882\n"
     ]
    }
   ],
   "source": [
    "ngb_pred_2 = np.zeros((target2.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    ngb.fit(tr_x,\n",
    "            tr_y, val_x, val_y, early_stopping_rounds = 2000)\n",
    "    pred = ngb.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = ngb.predict(target2) / 15\n",
    "    ngb_pred_2 += sub_pred\n",
    "print(f'\\n{ngb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(random_state = 718, max_depth = 5, n_estimators = 20000, learning_rate = .02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's l1: 51.583\ttraining's l2: 4678.24\tvalid_1's l1: 68.7999\tvalid_1's l2: 8329.61\n",
      "FOLD MAE = 68.79993446563824\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's l1: 64.893\ttraining's l2: 7288.94\tvalid_1's l1: 73.6322\tvalid_1's l2: 10883.6\n",
      "FOLD MAE = 73.63224306104472\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[565]\ttraining's l1: 46.4971\ttraining's l2: 3842.53\tvalid_1's l1: 72.9292\tvalid_1's l2: 8635.33\n",
      "FOLD MAE = 72.92923548471887\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2014]\ttraining's l1: 30.9305\ttraining's l2: 1698.42\tvalid_1's l1: 64.6994\tvalid_1's l2: 8491.1\n",
      "FOLD MAE = 64.69940192011973\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[521]\ttraining's l1: 47.5238\ttraining's l2: 4014.36\tvalid_1's l1: 68.5236\tvalid_1's l2: 7332.44\n",
      "FOLD MAE = 68.52359588970029\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's l1: 58.6761\ttraining's l2: 5974.16\tvalid_1's l1: 79.8255\tvalid_1's l2: 11674.4\n",
      "FOLD MAE = 79.82554148205263\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[967]\ttraining's l1: 39.7423\ttraining's l2: 2826.4\tvalid_1's l1: 65.7258\tvalid_1's l2: 6962.5\n",
      "FOLD MAE = 65.72582316307815\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttraining's l1: 52.4933\ttraining's l2: 4897.05\tvalid_1's l1: 77.173\tvalid_1's l2: 9140.12\n",
      "FOLD MAE = 77.17301997694408\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttraining's l1: 61.2894\ttraining's l2: 6486.59\tvalid_1's l1: 69.7444\tvalid_1's l2: 8627.7\n",
      "FOLD MAE = 69.74440044017858\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1080]\ttraining's l1: 37.6153\ttraining's l2: 2498.45\tvalid_1's l1: 81.0433\tvalid_1's l2: 11140\n",
      "FOLD MAE = 81.04333603138257\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[581]\ttraining's l1: 45.751\ttraining's l2: 3686.17\tvalid_1's l1: 74.1224\tvalid_1's l2: 9800.29\n",
      "FOLD MAE = 74.12238684381184\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2829]\ttraining's l1: 24.9422\ttraining's l2: 1105.2\tvalid_1's l1: 68.4952\tvalid_1's l2: 7479.08\n",
      "FOLD MAE = 68.49515604771106\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[851]\ttraining's l1: 41.8789\ttraining's l2: 3099.2\tvalid_1's l1: 71.8964\tvalid_1's l2: 10647.2\n",
      "FOLD MAE = 71.89640587972679\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1189]\ttraining's l1: 36.0067\ttraining's l2: 2276.66\tvalid_1's l1: 76.0713\tvalid_1's l2: 10106.1\n",
      "FOLD MAE = 76.07131509863788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttraining's l1: 55.7764\ttraining's l2: 5514.64\tvalid_1's l1: 67.7872\tvalid_1's l2: 7868.84\n",
      "FOLD MAE = 67.78715893461836\n",
      "\n",
      "LGBMRegressor MAE = 72.03126364795757\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idX1, val_idX1 in kf.split(X1):\n",
    "    tr_X1, val_X1 = X1.iloc[tr_idX1], X1.iloc[val_idX1]\n",
    "    tr_y, val_y = y1.iloc[tr_idX1], y1.iloc[val_idX1]\n",
    "    lgbm.fit(tr_X1, tr_y, eval_set = [(tr_X1, tr_y), (val_X1, val_y)], eval_metric = 'mean_absolute_error', early_stopping_rounds = 2000, verbose = 5000)\n",
    "    pred = lgbm.predict(val_X1)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = lgbm.predict(target1) / 15\n",
    "    lgbm_pred_1 += sub_pred\n",
    "print(f'\\n{lgbm.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1421]\ttraining's l1: 25.1178\ttraining's l2: 1233.21\tvalid_1's l1: 40.5822\tvalid_1's l2: 2528.15\n",
      "FOLD MAE = 40.582210737944386\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[522]\ttraining's l1: 31.882\ttraining's l2: 1998.65\tvalid_1's l1: 54.7419\tvalid_1's l2: 6554.52\n",
      "FOLD MAE = 54.741861447963466\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's l1: 41.0974\ttraining's l2: 3291.3\tvalid_1's l1: 43.4276\tvalid_1's l2: 3314.58\n",
      "FOLD MAE = 43.4275711272845\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's l1: 30.7701\ttraining's l2: 1826.08\tvalid_1's l1: 48.9874\tvalid_1's l2: 5498.3\n",
      "FOLD MAE = 48.98741453258124\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[363]\ttraining's l1: 35.4634\ttraining's l2: 2511.62\tvalid_1's l1: 41.423\tvalid_1's l2: 2778.72\n",
      "FOLD MAE = 41.423047648404925\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's l1: 30.3267\ttraining's l2: 1763.12\tvalid_1's l1: 40.8978\tvalid_1's l2: 3536.41\n",
      "FOLD MAE = 40.89783102474526\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[670]\ttraining's l1: 30.6494\ttraining's l2: 1822.95\tvalid_1's l1: 45.0603\tvalid_1's l2: 4309.68\n",
      "FOLD MAE = 45.06030568528248\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[341]\ttraining's l1: 36.0377\ttraining's l2: 2562.56\tvalid_1's l1: 38.5125\tvalid_1's l2: 2502.19\n",
      "FOLD MAE = 38.5125378258836\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1577]\ttraining's l1: 25.3846\ttraining's l2: 1238.62\tvalid_1's l1: 40.1731\tvalid_1's l2: 2783.61\n",
      "FOLD MAE = 40.17305642389921\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[353]\ttraining's l1: 34.2198\ttraining's l2: 2233.36\tvalid_1's l1: 58.7161\tvalid_1's l2: 7719.58\n",
      "FOLD MAE = 58.71611587491516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[349]\ttraining's l1: 35.0452\ttraining's l2: 2476.79\tvalid_1's l1: 45.9283\tvalid_1's l2: 3964.26\n",
      "FOLD MAE = 45.928289314979494\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's l1: 37.1007\ttraining's l2: 2704.71\tvalid_1's l1: 47.5237\tvalid_1's l2: 4264.53\n",
      "FOLD MAE = 47.52367919285359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[647]\ttraining's l1: 30.1908\ttraining's l2: 1783.95\tvalid_1's l1: 50.2047\tvalid_1's l2: 4481.71\n",
      "FOLD MAE = 50.20467073932573\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's l1: 36.6966\ttraining's l2: 2690.57\tvalid_1's l1: 45.9191\tvalid_1's l2: 3793.18\n",
      "FOLD MAE = 45.919054602133514\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\ttraining's l1: 35.2978\ttraining's l2: 2504.03\tvalid_1's l1: 43.8009\tvalid_1's l2: 4616.99\n",
      "FOLD MAE = 43.80092589776246\n",
      "\n",
      "LGBMRegressor MAE = 45.7265714717306\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred_2 = np.zeros((target2.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    \n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], eval_metric = 'mean_absolute_error', early_stopping_rounds = 2000, verbose = 5000)\n",
    "    pred = lgbm.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    mae_list.append(mae)\n",
    "    sub_pred = lgbm.predict(target2) / 15\n",
    "    lgbm_pred_2 += sub_pred\n",
    "print(f'\\n{lgbm.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['중식계'] = (lgbm_pred_1 + ngb_pred_1 + cb_pred_1) / 3\n",
    "submission['석식계'] = (lgbm_pred_2 + ngb_pred_2 + cb_pred_2) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>중식계</th>\n",
       "      <th>석식계</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>1021.270296</td>\n",
       "      <td>367.276235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>955.712339</td>\n",
       "      <td>424.324562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>637.998207</td>\n",
       "      <td>236.101793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>1267.976615</td>\n",
       "      <td>554.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>1036.126351</td>\n",
       "      <td>494.879986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           일자          중식계         석식계\n",
       "0  2021-01-27  1021.270296  367.276235\n",
       "1  2021-01-28   955.712339  424.324562\n",
       "2  2021-01-29   637.998207  236.101793\n",
       "3  2021-02-01  1267.976615  554.425200\n",
       "4  2021-02-02  1036.126351  494.879986"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49252.6861395934, 24129.579534888042)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.중식계.sum(), submission.석식계.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"0728.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
